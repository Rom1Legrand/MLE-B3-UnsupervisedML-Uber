{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Uber_logo_2018.svg/1024px-Uber_logo_2018.svg.png\" alt=\"UBER LOGO\" width=\"50%\" />\n",
    "\n",
    "# UBER Pickups \n",
    "## Company's Description üìá\n",
    "\n",
    "<a href=\"http://uber.com/\" target=\"_blank\">Uber</a> est l'une des startups les plus c√©l√®bres au monde. Elle a commenc√© comme une application de covoiturage pour les personnes qui ne pouvaient pas se permettre un taxi. Maintenant, Uber a √©tendu ses activit√©s √† la livraison de nourriture,  <a href=\"https://www.ubereats.com/fr-en\" target=\"_blank\">Uber Eats</a>, livraison de colis, au transport de marchandises et m√™me au transport urbain avec <a href=\"https://www.uber.com/fr/en/ride/uber-bike/\" target=\"_blank\"> Jump Bike</a> and <a href=\"https://www.li.me/\" target=\"_blank\"> Lime </a> que l'entreprise a financ√©s. \n",
    "\n",
    "\n",
    "L'objectif de l'entreprise est de r√©volutionner le transport √† travers le monde. Elle op√®re d√©sormais dans environ 70 pays et 900 villes, et g√©n√®re un chiffre d'affaires de plus de 14 milliards de dollars ! üòÆ\n",
    "## Projet üöß\n",
    "\n",
    "L'une des principales difficult√©s que l'√©quipe d'Uber a identifi√©es est que parfois, les conducteurs ne sont pas disponibles lorsque les utilisateurs en ont besoin. Par exemple, un utilisateur pourrait se trouver dans le quartier financier de San Francisco alors que les chauffeurs Uber recherchent des clients dans le quartier de Castro.\n",
    "\n",
    "M√™me si les deux quartiers ne sont pas tr√®s √©loign√©s, les utilisateurs doivent quand m√™me attendre 10 √† 15 minutes avant d'√™tre pris en charge, ce qui est trop long. Les recherches d'Uber montrent que les utilisateurs acceptent d'attendre 5 √† 7 minutes, sinon ils annuleront leur trajet.\n",
    "\n",
    "Par cons√©quent, l'√©quipe de donn√©es d'Uber souhaite travailler sur un projet o√π leur application recommanderait des zones chaudes dans les grandes villes √† tout moment de la journ√©e.\n",
    "## Objectifs üéØ\n",
    "\n",
    "Uber dispose d√©j√† de donn√©es sur les prises en charge dans les grandes villes. Votre objectif est de cr√©er des algorithmes qui d√©termineront les zones chaudes o√π les conducteurs devraient se trouver. Par cons√©quent, vous allez :\n",
    "\n",
    "* Cr√©er un algorithme pour trouver les zones chaudes.\n",
    "* Visualiser les r√©sultats sur un tableau de bord attrayant.\n",
    "## Scope du projet üñºÔ∏è\n",
    "\n",
    "Pour commencer, Uber souhaite essayer cette fonctionnalit√© dans la ville de New York. Par cons√©quent, vous vous concentrerez uniquement sur cette ville. Les donn√©es peuvent √™tre trouv√©es ici :\n",
    "\n",
    "üëâüëâ<a href=\"https://full-stack-bigdata-datasets.s3.eu-west-3.amazonaws.com/Machine+Learning+non+Supervis%C3%A9/Projects/uber-trip-data.zip\" target=\"_blank\"> Uber Trip Data</a> üëàüëà\n",
    "\n",
    "**Vous ne devez vous concentrer que sur la ville de New York pour ce projet.**\n",
    "## Deliverable üì¨\n",
    "\n",
    "Pour mener √† bien ce projet, votre √©quipe devrait :\n",
    "\n",
    "* Avoir une carte avec des zones chaudes en utilisant n'importe quelle biblioth√®que Python (plotly ou autre).\n",
    "* Vous devriez au moins d√©crire les zones chaudes par jour de la semaine.\n",
    "* Comparer les r√©sultats avec au moins deux algorithmes non supervis√©s comme KMeans et DBScan.\n",
    "\n",
    "Vos cartes devraient ressembler √† quelque chose comme ceci :\n",
    "\n",
    "<img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Clusters_uber_pickups.png\" alt=\"Uber Cluster Map\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBAIRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 1 : Pr√©paration et visualisation des donn√©es\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement des donn√©es de 2014\n",
    "# On charge tous les fichiers d'Uber\n",
    "df1 = pd.read_csv(\"src/uber-raw-data-apr14.csv\")\n",
    "df2 = pd.read_csv(\"src/uber-raw-data-may14.csv\") \n",
    "df3 = pd.read_csv(\"src/uber-raw-data-jun14.csv\")\n",
    "df4 = pd.read_csv(\"src/uber-raw-data-jul14.csv\")\n",
    "df5 = pd.read_csv(\"src/uber-raw-data-aug14.csv\")\n",
    "df6 = pd.read_csv(\"src/uber-raw-data-sep14.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head de df1 √† df6\n",
    "print(df1.head())\n",
    "print(df2.head())\n",
    "print(df3.head())\n",
    "print(df4.head())\n",
    "print(df5.head())\n",
    "print(df6.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure identique : concat√©nons les df de courses de d'Avril √† Septembre 2014 en un seul df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du dataset complet: (4534327, 4)\n"
     ]
    }
   ],
   "source": [
    "# 2. Concat√©nation des dataframes\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6], axis=0)\n",
    "print(\"Taille du dataset complet:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4,5 millions de lignes pour 2014 ! Regardons les deux derniers fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chargement des donn√©es de 2015 et du dernier fichier taxi_zone\n",
    "df7 = pd.read_csv(\"src/uber-raw-data-janjune-15.csv\")\n",
    "df8 = pd.read_csv(\"src/taxi-zone-lookup.csv\")\n",
    "\n",
    "# head de df7 et df8\n",
    "print(df7.head())\n",
    "print(df8.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pour les donn√©es de 2015 les donn√©es sont diff√©rentes : il n'y a pas de donn√©es GPS, mais une locationID associ√© √† une base. A l'√©poque, √† NY, chaque chauffeur √©tant rattach√© √† une base UBER sp√©cifique.\n",
    "\n",
    "- Techniquement nous pourrions faire une jointure entre les donn√©es 2015 et le taxi-zone-lookup.csv sur locationID et utiliser les coordonn√©es moyennes/centrales de chaque zone comme point de r√©f√©rence. Mais nous aurions unbe perte de pr√©cision car on aurait uniquement le centre de la zone et non le point exact de prise en charge comme pour les datas de 2014.\n",
    "\n",
    "- Ayant d√©j√† largement assez de data, ous nous concentrerons donc sur 2014 et sur le \"df\" d√©j√† concat√©n√©\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Date/Time           Lat           Lon     Base\n",
      "count             4534327  4.534327e+06  4.534327e+06  4534327\n",
      "unique             260093           NaN           NaN        5\n",
      "top     4/7/2014 20:21:00           NaN           NaN   B02617\n",
      "freq                   97           NaN           NaN  1458853\n",
      "mean                  NaN  4.073926e+01 -7.397302e+01      NaN\n",
      "std                   NaN  3.994991e-02  5.726670e-02      NaN\n",
      "min                   NaN  3.965690e+01 -7.492900e+01      NaN\n",
      "25%                   NaN  4.072110e+01 -7.399650e+01      NaN\n",
      "50%                   NaN  4.074220e+01 -7.398340e+01      NaN\n",
      "75%                   NaN  4.076100e+01 -7.396530e+01      NaN\n",
      "max                   NaN  4.211660e+01 -7.206660e+01      NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas de valeurs manquantes √† traiter. Passons √† la pr√©aprations des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Pr√©paration des donn√©es temporelles\n",
    "\n",
    "# Conversion de la colonne Date/Time en datetime\n",
    "df['Date'] = pd.to_datetime(df['Date/Time'])\n",
    "\n",
    "# Cr√©ation des colonnes pour les analyses temporelles\n",
    "df['weekday'] = df['Date'].dt.dayofweek  # 0 = Lundi, 6 = Dimanche\n",
    "df['hour'] = df['Date'].dt.hour\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualisations de base\n",
    "# 4.1 Distribution des courses par jour de la semaine\n",
    "jours = ['Lundi', 'Mardi', 'Mercredi', 'Jeudi', 'Vendredi', 'Samedi', 'Dimanche']\n",
    "fig1 = px.histogram(df, \n",
    "                   x='weekday',\n",
    "                   title='Distribution des courses par jour de la semaine',\n",
    "                   labels={'weekday': 'Jour de la semaine'},\n",
    "                   category_orders={'weekday': list(range(7))})\n",
    "fig1.update_xaxes(ticktext=jours, tickvals=list(range(7)))\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Journ√©e la plus charg√©e : jeudi\n",
    "- Journ√©e la moins charg√©e : dimanche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Distribution des courses par heure\n",
    "fig2 = px.histogram(df, \n",
    "                   x='hour',\n",
    "                   title='Distribution des courses par heure',\n",
    "                   labels={'hour': 'Heure de la journ√©e'})\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 17h, l'heure de pointe\n",
    "- 2h du matin, l'heure creuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Carte de chaleur temporelle (jour x heure)\n",
    "# Cr√©ation d'un tableau crois√© pour la heatmap\n",
    "heatmap_data = pd.crosstab(df['weekday'], df['hour'])\n",
    "\n",
    "fig3 = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_data,\n",
    "    x=list(range(24)),\n",
    "    y=jours,\n",
    "    colorscale='Viridis'))\n",
    "\n",
    "fig3.update_layout(\n",
    "    title='Carte de chaleur des courses par jour et heure',\n",
    "    xaxis_title='Heure de la journ√©e',\n",
    "    yaxis_title='Jour de la semaine'\n",
    ")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pics d'activit√© :\n",
    "1. Comme vu pr√©cedement, les pics sont du lundi au vendredi entre 15h-20h\n",
    "2. On Constate pour le vendredi et le samedi un d√©calage de l'activit√© apr√®s 21h\n",
    "\n",
    "P√©riodes calmes :\n",
    "1. Entre 0h et 5h tous les jours\n",
    "2. Avec un d√©calage en d√©but de matin√©e le week end \n",
    "\n",
    "Conclusions :\n",
    "1. La demande suit clairement les rythmes de travail en semaine avec des pics aux heures de sortie de bureau\n",
    "2. Le weekend montre des patterns diff√©rents, orient√©s loisirs/sorties\n",
    "3. La nuit profonde (2h-4h) repr√©sente syst√©matiquement un creux d'activit√© important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.4 Carte des points de ramassage (√©chantillon pour la visualisation)\n",
    "sample_size = min(10000, len(df))  # On limite √† 10000 points pour la visualisation\n",
    "df_sample = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "fig4 = px.scatter_mapbox(df_sample, \n",
    "                        lat='Lat', \n",
    "                        lon='Lon',\n",
    "                        title='Points de ramassage Uber √† New York',\n",
    "                        zoom=10,\n",
    "                        mapbox_style=\"carto-positron\")\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyse descriptive:\n",
      "Nombre total de courses: 4534327\n",
      "\n",
      "Distribution par jour:\n",
      "weekday\n",
      "0    541472\n",
      "1    663789\n",
      "2    696488\n",
      "3    755145\n",
      "4    741139\n",
      "5    646114\n",
      "6    490180\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution par heure:\n",
      "hour\n",
      "0     103836\n",
      "1      67227\n",
      "2      45865\n",
      "3      48287\n",
      "4      55230\n",
      "5      83939\n",
      "6     143213\n",
      "7     193094\n",
      "8     190504\n",
      "9     159967\n",
      "10    159148\n",
      "11    165703\n",
      "12    170452\n",
      "13    195877\n",
      "14    230625\n",
      "15    275466\n",
      "16    313400\n",
      "17    336190\n",
      "18    324679\n",
      "19    294513\n",
      "20    284604\n",
      "21    281460\n",
      "22    241858\n",
      "23    169190\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Sauvegarde du DataFrame nettoy√© pour les analyses suivantes\n",
    "# On garde uniquement les colonnes n√©cessaires\n",
    "colonnes_a_garder = ['Lat', 'Lon', 'weekday', 'hour', 'month', 'day']\n",
    "df_clean = df[colonnes_a_garder]\n",
    "df_clean.to_csv('src/uber_dfclean.csv', index=False)\n",
    "\n",
    "print(\"\\nAnalyse descriptive:\")\n",
    "print(\"Nombre total de courses:\", len(df))\n",
    "print(\"\\nDistribution par jour:\")\n",
    "print(df['weekday'].value_counts().sort_index())\n",
    "print(\"\\nDistribution par heure:\")\n",
    "print(df['hour'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
